{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc =SparkContext.getOrCreate()\n",
    "from pyspark.sql import SQLContext\n",
    "trurl='/home/aaftab/Dropbox/Techsoc/train_techsoc.csv'\n",
    "tsturl='/home/aaftab/Dropbox/Techsoc/test_techsoc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.addFile(trurl)\n",
    "sc.addFile(tsturl)\n",
    "\n",
    "sqlcontext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdf=sqlcontext.read.csv(SparkFiles.get('train_techsoc.csv'), header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstdf=sqlcontext.read.csv(SparkFiles.get('test_techsoc.csv'), header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- epoch: string (nullable = true)\n",
      " |-- sat_id: integer (nullable = true)\n",
      " |-- x: double (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      " |-- z: double (nullable = true)\n",
      " |-- Vx: double (nullable = true)\n",
      " |-- Vy: double (nullable = true)\n",
      " |-- Vz: double (nullable = true)\n",
      " |-- x_sim: double (nullable = true)\n",
      " |-- y_sim: double (nullable = true)\n",
      " |-- z_sim: double (nullable = true)\n",
      " |-- Vx_sim: double (nullable = true)\n",
      " |-- Vy_sim: double (nullable = true)\n",
      " |-- Vz_sim: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------+------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------------+-------------------+-------------------+------------------+-------------------+\n",
      "|id |epoch                  |sat_id|x                  |y                 |z                  |Vx                 |Vy                |Vz                 |x_sim              |y_sim              |z_sim              |Vx_sim             |Vy_sim            |Vz_sim             |\n",
      "+---+-----------------------+------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------------+-------------------+-------------------+------------------+-------------------+\n",
      "|0  |2014-01-01T00:00:00.000|0     |-20551.542729729616|30442.183965740267|-48103.896802169125|-2.1078805534520573|-8.838164531369227|-4.692610127789226 |-20522.087696771745|30489.622268523894 |-48134.67384466676 |-2.106079702642676 |-8.830028584063664|-4.697368138813824 |\n",
      "|1  |2014-01-01T00:46:43.000|0     |-24524.19717481988 |3758.91402204878  |-56744.85999899573 |-0.7022151641678598|-9.915381027376242|-1.4221032244854699|-24495.94910759859 |3827.474600049883  |-56794.23547149369 |-0.7047994696597658|-9.908881372160106|-1.4306267124446872|\n",
      "|2  |2014-01-01T01:33:26.001|0     |-24549.751724666097|-23625.61804097102|-56249.31958400319 |0.6438391870511615 |-9.393007872226981|1.6782129826972159 |-24533.911749531013|-23545.490604955237|-56325.64406064411 |0.6379096857425423 |-9.391303365984136|1.6680323507242103 |\n",
      "|3  |2014-01-01T02:20:09.001|0     |-21230.174839276864|-47925.39982525879|-48085.39643914685 |1.660679321707133  |-7.829425025207068|3.9964790599848854 |-21233.351704453824|-47848.26674715427 |-48188.986570848894|1.6533382075448801 |-7.83276763306095 |3.987639911859377  |\n",
      "|4  |2014-01-01T03:06:52.002|0     |-15592.870340029653|-67135.12547472825|-34668.440811751774|2.303292882859401  |-5.847493579330634|5.441307751651304  |-15616.695660273213|-67072.95398235874 |-34792.57872728826 |2.2960407898105006 |-5.854192243686964|5.43558585956124   |\n",
      "+---+-----------------------+------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------------+-------------------+-------------------+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trdf.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            features|                Vy|\n",
      "+--------------------+------------------+\n",
      "|[-20522.087696771...|-8.838164531369227|\n",
      "|[-24495.949107598...|-9.915381027376242|\n",
      "|[-24533.911749531...|-9.393007872226981|\n",
      "|[-21233.351704453...|-7.829425025207068|\n",
      "|[-15616.695660273...|-5.847493579330634|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['x_sim','y_sim','z_sim','Vx_sim','Vy_sim','Vz_sim','sat_id'], outputCol = 'features')\n",
    "trd=vectorAssembler.transform(trdf)\n",
    "trd=trd.select(['features','Vy'])\n",
    "trd.show(5)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "lr = GBTRegressor(featuresCol = 'features', labelCol='Vy')\n",
    "lr_model = lr.fit(trd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[-67817.397487337...|\n",
      "|[-69478.899261576...|\n",
      "|[-69610.589087625...|\n",
      "|[-68136.264984711...|\n",
      "|[-64959.510617139...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['x_sim','y_sim','z_sim','Vx_sim','Vy_sim','Vz_sim'], outputCol = 'features')\n",
    "tstd=vectorAssembler.transform(tstdf)\n",
    "tstd=tstd.select(['features'])\n",
    "tstd.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lr_pred=lr_model.transform(tstd)\n",
    "lr_pred.toPandas().to_csv('Vypred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
